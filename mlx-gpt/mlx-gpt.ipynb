{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7861a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import mlx.utils as utils\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(list(set(text)))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(''.join(vocab))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67516c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "iots = {i: c for i, c in enumerate(vocab)}\n",
    "stoi = {c: i for i, c in enumerate(vocab)}\n",
    "def encode(x): return [stoi[c] for c in x]\n",
    "def decode(x): return ''.join([iots[i] for i in x])\n",
    "\n",
    "\n",
    "print(encode(\"hello world\"))\n",
    "print(decode(encode(\"hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdab1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encode(text)\n",
    "split = int(0.9 * len(data))\n",
    "train_data = data[:split]\n",
    "val_data = data[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097c735",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_len = 128\n",
    "n_emb = 128\n",
    "dropout = 0.1\n",
    "head_size = 128\n",
    "n_heads = 4\n",
    "n_layers = 3\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "\n",
    "print(train_data[:ctx_len + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4307e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inputs: \", train_data[:ctx_len])\n",
    "print(\"labels \", train_data[1:ctx_len+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b266147",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mx.array([train_data[i: i+ctx_len]\n",
    "                   for i in range(0, len(train_data) - ctx_len, ctx_len)])\n",
    "y_train = mx.array([train_data[i+1: i+ctx_len+1]\n",
    "                   for i in range(0, len(train_data) - ctx_len, ctx_len)])\n",
    "X_val = mx.array([train_data[i: i+ctx_len]\n",
    "                 for i in range(0, len(val_data) - ctx_len, ctx_len)])\n",
    "y_val = mx.array([train_data[i+1: i + ctx_len+1]\n",
    "                 for i in range(0, len(val_data) - ctx_len, ctx_len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ebf791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, y, b_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        ix = np.arange(X.shape[0])\n",
    "        np.random.shuffle(ix)\n",
    "        ix = mx.array(ix)\n",
    "        X = X[ix]\n",
    "        y = y[ix]\n",
    "\n",
    "    for i in range(0, X.shape[0], b_size):\n",
    "        input = X[i: i+b_size]\n",
    "        label = y[i: i+b_size]\n",
    "        yield input, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.k_proj = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.q_proj = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.v_proj = nn.Linear(n_emb, head_size, bias=False)\n",
    "\n",
    "        indices = mx.arange(ctx_len)\n",
    "        mask = indices[:, None] < indices[None]\n",
    "        self.causal_mask = mask * -1e9\n",
    "        # self.c_proj = nn.Linear(head_size, n_emb)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        K = self.k_proj(x)\n",
    "        Q = self.q_proj(x)\n",
    "        V = self.v_proj(x)\n",
    "        attn_weights = (Q @ K.transpose([0, 2, 1])) / math.sqrt(self.head_size)\n",
    "        casual_mask = self.causal_mask[:T, :T]\n",
    "        attn_weights = attn_weights + casual_mask\n",
    "        attn_weights = mx.softmax(attn_weights, axis=-1)\n",
    "        attn_weights = self.resid_dropout(attn_weights)\n",
    "        o = (attn_weights @ V)\n",
    "        # o = self.c_proj(self.resid_dropout(o))\n",
    "        # o = self.resid_dropout(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.heads = [Attention(head_size//n_heads) for _ in range(n_heads)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return mx.concatenate([head(x) for head in self.heads], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882c3b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e94295",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(n_emb, 4*n_emb)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.c_proj = nn.Linear(4*n_emb, n_emb)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.gelu(self.c_fc(x))\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f1569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp = MLP()\n",
    "        self.mha = MultiHeadedAttention()\n",
    "        self.ln_1 = nn.LayerNorm(dims=n_emb)\n",
    "        self.ln_2 = nn.LayerNorm(dims=n_emb)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x + self.mha(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.wte = nn.Embedding(vocab_size, n_emb)\n",
    "        self.wpe = nn.Embedding(ctx_len, n_emb)\n",
    "        self.blocks = nn.Sequential(*[Block() for _ in range(n_layers)])\n",
    "        self.ln_f = nn.LayerNorm(dims=n_emb)\n",
    "        self.lm_head = nn.Linear(n_emb, vocab_size)\n",
    "        self._init_parameters()\n",
    "        total_params = sum(\n",
    "            [p.size for n, p in utils.tree_flatten(self.parameters())])\n",
    "        print(f\"Total params: {(total_params / 1e6):.3f}M\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        B, T = x.shape  # (B = batch_size, T = ctx_len)\n",
    "        tok_emb = self.wte(x)  # (B, T, n_emb)\n",
    "        pos_emb = self.wpe(mx.arange(T))  # (T, n_emb)\n",
    "        x = tok_emb + pos_emb  # (B, T, n_emb)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, max_new_tokens):\n",
    "        ctx = mx.zeros((1, 1), dtype=mx.int32)\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(ctx[:, -ctx_len:])\n",
    "            logits = logits[:, -1, :]\n",
    "            next_tok = mx.random.categorical(logits, num_samples=1)\n",
    "            ctx = mx.concatenate((ctx, next_tok), axis=1)\n",
    "        return ctx\n",
    "\n",
    "    def _init_parameters(self):\n",
    "        normal_init = nn.init.normal(mean=0.0, std=0.02)\n",
    "        residual_init = nn.init.normal(\n",
    "            mean=0.0, std=(0.02 / math.sqrt(2 * n_layers)))\n",
    "        new_params = []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, nn.layers.linear.Linear):\n",
    "                if 'c_proj' in name:\n",
    "                    new_params.append(\n",
    "                        (name + '.weight', residual_init(module.weight)))\n",
    "                else:\n",
    "                    new_params.append(\n",
    "                        (name + '.weight', normal_init(module.weight)))\n",
    "                if 'bias' in module:\n",
    "                    new_params.append(\n",
    "                        (name + '.bias', mx.zeros(module.bias.shape)))\n",
    "            elif isinstance(module, nn.layers.embedding.Embedding):\n",
    "                new_params.append(\n",
    "                    (name + '.weight', normal_init(module.weight)))\n",
    "        self = self.update(utils.tree_unflatten(new_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0467258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | train = 3.0429 | val = 2.6857\n",
      "Epoch  1 | train = 2.5997 | val = 2.4566\n",
      "Epoch  2 | train = 2.3942 | val = 2.2620\n",
      "Epoch  3 | train = 2.2442 | val = 2.1274\n",
      "Epoch  4 | train = 2.1144 | val = 1.9901\n",
      "Epoch  5 | train = 1.9933 | val = 1.8585\n",
      "Epoch  6 | train = 1.8854 | val = 1.7536\n",
      "Epoch  7 | train = 1.7985 | val = 1.6778\n",
      "Epoch  8 | train = 1.7311 | val = 1.6095\n",
      "Epoch  9 | train = 1.6791 | val = 1.5661\n",
      "Epoch 10 | train = 1.6366 | val = 1.5311\n",
      "Epoch 11 | train = 1.6025 | val = 1.5045\n",
      "Epoch 12 | train = 1.5760 | val = 1.4750\n",
      "Epoch 13 | train = 1.5528 | val = 1.4576\n",
      "Epoch 14 | train = 1.5318 | val = 1.4413\n",
      "Epoch 15 | train = 1.5145 | val = 1.4254\n",
      "Epoch 16 | train = 1.4991 | val = 1.4080\n",
      "Epoch 17 | train = 1.4839 | val = 1.3884\n",
      "Epoch 18 | train = 1.4723 | val = 1.3807\n",
      "Epoch 19 | train = 1.4615 | val = 1.3732\n"
     ]
    }
   ],
   "source": [
    "def loss_fn(model, x, y):\n",
    "    logits = model(x)\n",
    "    B, T, C = logits.shape  # (batch_size, seq_len, vocab_size)\n",
    "    logits = logits.reshape(B*T, C)\n",
    "    y = y.reshape(B*T)\n",
    "    loss = nn.losses.cross_entropy(logits, y, reduction='mean')\n",
    "    return loss\n",
    "\n",
    "\n",
    "model = GPT()\n",
    "mx.eval(model.parameters())  # Create the model params (mlx is lazy evaluation)\n",
    "loss_and_grad = nn.value_and_grad(model, loss_fn)\n",
    "optimizer = optim.AdamW(learning_rate=lr)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train(True)\n",
    "    running_loss = 0\n",
    "    batch_cnt = 0\n",
    "    for input, label in get_batches(X_train, y_train, batch_size):\n",
    "        batch_cnt += 1\n",
    "        loss, grads = loss_and_grad(model, input, label)\n",
    "        optimizer.update(model, grads)\n",
    "        running_loss += loss.item()\n",
    "        # compute new parameters and optimizer state\n",
    "        mx.eval(model.parameters(), optimizer.state)\n",
    "    avg_train_loss = running_loss / batch_cnt\n",
    "    model.train(False)  # set eval mode\n",
    "    running_loss = 0\n",
    "    batch_cnt = 0\n",
    "    for input, label in get_batches(X_val, y_val, batch_size):\n",
    "        batch_cnt += 1\n",
    "        loss = loss_fn(model, input, label)\n",
    "        running_loss += loss.item()\n",
    "    avg_val_loss = running_loss / batch_cnt\n",
    "    print(\n",
    "        f\"Epoch {epoch:2} | train = {avg_train_loss:.4f} | val = {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "087976c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "That be doubtled, but lady the false can to away. Guliet:\n",
      "So wady it all in the grows of girl still.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Bou give to him.\n",
      "\n",
      "ISABELLA:\n",
      "A patient to unjurniors,\n",
      "Alas, take to him ill be proad ministate.\n",
      "\n",
      "BENVOLIO:\n",
      "To make you his\n",
      "youness dear?\n",
      "\n",
      "QUEEN MARGARET:\n",
      "How no.\n",
      "Lay, long.\n",
      "\n",
      "CORIOLANUS:\n",
      "My life honourable repurage us, stays\n",
      "That I see three it know up, my lord.\n",
      "\n",
      "CAMILLO:\n",
      "They dost Cliffondly? I here thumb, I'll well;\n",
      "Or not eagle steel the playes, end your glown,\n",
      "But he finet armanly spake, which he dods maid\n",
      "To make into be titl title your wexts,\n",
      "For you royal weeping tune that they bear in me weight;\n",
      "The will will I stroke your tongue,\n",
      "That hastised the flatter of do shall be tyrangled.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "What I do you come to your day; hast let him\n",
      "The jalle of senator'd title to justifiation\n",
      "you be so you the England, as have with you:\n",
      "I doss that I will sellow; for here nood,\n",
      "Some brew I lost by thy desire ring: the nobless,\n",
      "You were else not to of stears and all their\n"
     ]
    }
   ],
   "source": [
    "completion = decode(model.generate(1000)[0].tolist())\n",
    "print(completion)\n",
    "with open('completions.txt', 'w') as f:\n",
    "    f.write(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b78da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
